{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessed_mnist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d44321ddd5a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpreprocessed_mnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'preprocessed_mnist'"
     ]
    }
   ],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-efb47621fe3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mHiddenLayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-efb47621fe3b>\u001b[0m in \u001b[0;36mHiddenLayer\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHiddenLayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class HiddenLayer:\n",
    "    def __init__(self, M, D, activation=tf.nn.relu):\n",
    "        self.W = self.init_w(M,D)\n",
    "        self.b = self.init_b(D)\n",
    "        self.activation = activation\n",
    "\n",
    "    def init_w(self, M, D):\n",
    "        #XAVIER UNIFORM WEIGHT INITIALIZATION\n",
    "        return tf.Variable(initial_value = np.random.randn(M, D) / np.sqrt(M+D),\n",
    "                           dtype='float32'\n",
    "                           )\n",
    "\n",
    "    def init_b(self, D):\n",
    "        #INITIALIZE THE BIAS TERM WITH ZEROS\n",
    "        return tf.Variable(initial_value = np.zeros(D),\n",
    "                           dtype='float32')\n",
    "\n",
    "    def get_params(self):\n",
    "        #get parameters from hidden layer\n",
    "        return [self.W, self.b]\n",
    "\n",
    "    def get_layer_size(self):\n",
    "        return self.D\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.activation == tf.nn.relu:\n",
    "            Z=self.activation(tf.matmul(X,self.W) + self.b)\n",
    "\n",
    "        else:\n",
    "            Z= (tf.matmul(X,self.W) + self.b)\n",
    "\n",
    "        # Calculate batch mean and variance\n",
    "        batch_mean, batch_var = tf.nn.moments(Z, [0])\n",
    "\n",
    "        # Apply the  batch normalizing transform\n",
    "        Z_HAT = (Z - batch_mean) / tf.sqrt(batch_var + 0.001)\n",
    "        return Z_HAT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-28fb61cd7bf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     def __init__(self, hidden_layer_sizes,\n\u001b[0;32m      4\u001b[0m                  \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-28fb61cd7bf5>\u001b[0m in \u001b[0;36mNeuralNetwork\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     def __init__(self, hidden_layer_sizes,\n\u001b[0;32m      4\u001b[0m                  \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                  \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5e-3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                  \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, hidden_layer_sizes,\n",
    "                 dataset,\n",
    "                 activation=tf.nn.relu,\n",
    "                 learning_rate=5e-3,\n",
    "                 iterations=25,\n",
    "                 batch_size=500\n",
    "                 ):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset=dataset\n",
    "\n",
    "\n",
    "    def generate_layers(self, first_layer_size, activation_layer_size):\n",
    "        layers = []\n",
    "        prev_layer_size = first_layer_size\n",
    "        for hidden_layer_size in self.hidden_layer_sizes:\n",
    "            hidden_layer = HiddenLayer(prev_layer_size, hidden_layer_size, self.activation)\n",
    "            layers.append(hidden_layer)\n",
    "            prev_layer_size = hidden_layer_size\n",
    "\n",
    "        activation_layer = HiddenLayer(prev_layer_size, activation_layer_size, activation=None)\n",
    "        layers.append(activation_layer)\n",
    "        return layers\n",
    "\n",
    "    def get_number_of_classes(self, target):\n",
    "        return  len(set(target))\n",
    "\n",
    "    def get_cost(self, Y, T):\n",
    "        cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=Y, labels=T))\n",
    "        return cost\n",
    "\n",
    "    def fit(self, print_period=45, show_fig=True):\n",
    "        #get dataset variables\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = self.dataset(flatten=True)\n",
    "\n",
    "        #make one-hot encoding for the classes\n",
    "        Ytrain_ind = self.y_hot_encoding(y_train)\n",
    "        Ytest_ind = self.y_hot_encoding(y_test)\n",
    "        Yval_ind = self.y_hot_encoding(y_val)\n",
    "\n",
    "        # initialize hidden layers\n",
    "        N, D = X_train.shape\n",
    "\n",
    "        #get number of classes\n",
    "        K=self.get_number_of_classes(target=y_train)\n",
    "\n",
    "        #generate layers\n",
    "        self.layers = self.generate_layers(first_layer_size=D,\n",
    "                                           activation_layer_size=K)\n",
    "\n",
    "\n",
    "\n",
    "        #define placeholders\n",
    "        X = tf.placeholder(dtype=tf.float32, shape=(None, D), name='X')\n",
    "        T = tf.placeholder(dtype=tf.float32, shape=(None, K), name='T')\n",
    "\n",
    "        #make feed forward to all layers\n",
    "        Z = X\n",
    "        for layer in self.layers:\n",
    "            Z = layer.forward(Z)\n",
    "\n",
    "        #latest feed forward layer is the activation layer\n",
    "        Y_predicted = Z\n",
    "\n",
    "        #get the cost of our prediction\n",
    "        cost=self.get_cost(Y=Y_predicted,T=T)\n",
    "\n",
    "        #define the trianing optimization\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=0.0015).minimize(cost)\n",
    "\n",
    "\n",
    "        # we'll use this to calculate the error rate\n",
    "        error_rate = tf.argmax(Y_predicted, 1)\n",
    "\n",
    "        costs = []\n",
    "\n",
    "        no_batches = self.get_number_of_batches(samples=N)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as session:\n",
    "            def validate(X_in,Y_out, Y_ind):\n",
    "                # call validation session\n",
    "                test_cost = session.run(cost, feed_dict={X: X_in, T: Y_ind})\n",
    "                # get error rate\n",
    "                prediction = session.run(error_rate, feed_dict={X: X_in})\n",
    "                accuracy = 100-100*self.error_rate(prediction, Y_out)\n",
    "                print(\"Cost and error rate at iteration i={0}, j={1}: Cost : {2} Accuracy: {3}\".format(i, j, test_cost, accuracy))\n",
    "                return test_cost\n",
    "\n",
    "            session.run(init)\n",
    "            for i in range(self.iterations):\n",
    "                for j in range(no_batches):\n",
    "                    #train\n",
    "                    Xbatch = X_train[j * self.batch_size:(j * self.batch_size + self.batch_size), ]\n",
    "                    Ybatch = Ytrain_ind[j * self.batch_size:(j * self.batch_size + self.batch_size), ]\n",
    "                    #call train session\n",
    "                    session.run(train_op, feed_dict={X: Xbatch, T: Ybatch})\n",
    "\n",
    "                    #validate\n",
    "                    if j % print_period == 0:\n",
    "                        costs.append(validate(X_val,y_val,Yval_ind))\n",
    "\n",
    "            print('------------------------------TEST------------------------------------')\n",
    "            # call validation session\n",
    "            validate(X_test,y_test,Ytest_ind)\n",
    "\n",
    "\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "    def error_rate(self, p, t):\n",
    "        return np.mean(p != t)\n",
    "\n",
    "    def get_number_of_batches(self, samples):\n",
    "        if self.batch_size is None:\n",
    "            self.batch_size = samples\n",
    "\n",
    "        batches = samples // self.batch_size\n",
    "        return batches\n",
    "\n",
    "    def y_hot_encoding(self, Y):\n",
    "        N = len(Y)\n",
    "        K = len(set(Y))\n",
    "        hot_encoding = np.zeros((N, K))\n",
    "        hot_encoding[np.arange(N), Y] = 1\n",
    "        return hot_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost and error rate at iteration i=0, j=0: Cost : 18862.59765625 Accuracy: 34.489999999999995\n",
      "Cost and error rate at iteration i=0, j=45: Cost : 4730.1826171875 Accuracy: 94.98\n",
      "Cost and error rate at iteration i=0, j=90: Cost : 3917.732177734375 Accuracy: 96.69\n",
      "Cost and error rate at iteration i=1, j=0: Cost : 3863.26953125 Accuracy: 96.78\n",
      "Cost and error rate at iteration i=1, j=45: Cost : 3673.3828125 Accuracy: 97.18\n",
      "Cost and error rate at iteration i=1, j=90: Cost : 3551.43408203125 Accuracy: 97.42\n",
      "Cost and error rate at iteration i=2, j=0: Cost : 3557.169921875 Accuracy: 97.37\n",
      "Cost and error rate at iteration i=2, j=45: Cost : 3500.29833984375 Accuracy: 97.57\n",
      "Cost and error rate at iteration i=2, j=90: Cost : 3435.52099609375 Accuracy: 97.72\n",
      "Cost and error rate at iteration i=3, j=0: Cost : 3477.7900390625 Accuracy: 97.63\n",
      "Cost and error rate at iteration i=3, j=45: Cost : 3466.06591796875 Accuracy: 97.54\n",
      "Cost and error rate at iteration i=3, j=90: Cost : 3388.30322265625 Accuracy: 97.95\n",
      "Cost and error rate at iteration i=4, j=0: Cost : 3409.85595703125 Accuracy: 97.9\n",
      "Cost and error rate at iteration i=4, j=45: Cost : 3398.94384765625 Accuracy: 97.78\n",
      "Cost and error rate at iteration i=4, j=90: Cost : 3376.880859375 Accuracy: 97.9\n",
      "Cost and error rate at iteration i=5, j=0: Cost : 3365.741943359375 Accuracy: 97.94\n",
      "Cost and error rate at iteration i=5, j=45: Cost : 3362.8779296875 Accuracy: 97.9\n",
      "Cost and error rate at iteration i=5, j=90: Cost : 3341.38818359375 Accuracy: 98.03\n",
      "Cost and error rate at iteration i=6, j=0: Cost : 3354.264892578125 Accuracy: 97.91\n",
      "Cost and error rate at iteration i=6, j=45: Cost : 3343.44189453125 Accuracy: 97.93\n",
      "Cost and error rate at iteration i=6, j=90: Cost : 3320.303955078125 Accuracy: 98.1\n",
      "Cost and error rate at iteration i=7, j=0: Cost : 3328.6357421875 Accuracy: 97.96\n",
      "Cost and error rate at iteration i=7, j=45: Cost : 3341.470947265625 Accuracy: 97.93\n",
      "Cost and error rate at iteration i=7, j=90: Cost : 3313.09765625 Accuracy: 98.09\n",
      "Cost and error rate at iteration i=8, j=0: Cost : 3301.489990234375 Accuracy: 98.04\n",
      "Cost and error rate at iteration i=8, j=45: Cost : 3306.421142578125 Accuracy: 97.98\n",
      "Cost and error rate at iteration i=8, j=90: Cost : 3307.852783203125 Accuracy: 97.97\n",
      "Cost and error rate at iteration i=9, j=0: Cost : 3280.896240234375 Accuracy: 98.2\n",
      "Cost and error rate at iteration i=9, j=45: Cost : 3275.979736328125 Accuracy: 98.1\n",
      "Cost and error rate at iteration i=9, j=90: Cost : 3311.583984375 Accuracy: 97.97\n",
      "Cost and error rate at iteration i=10, j=0: Cost : 3278.833984375 Accuracy: 98.1\n",
      "Cost and error rate at iteration i=10, j=45: Cost : 3269.041015625 Accuracy: 98.19\n",
      "Cost and error rate at iteration i=10, j=90: Cost : 3304.3466796875 Accuracy: 98.02\n",
      "Cost and error rate at iteration i=11, j=0: Cost : 3271.96875 Accuracy: 98.1\n",
      "Cost and error rate at iteration i=11, j=45: Cost : 3306.00634765625 Accuracy: 98.13\n",
      "Cost and error rate at iteration i=11, j=90: Cost : 3271.22314453125 Accuracy: 98.2\n",
      "Cost and error rate at iteration i=12, j=0: Cost : 3263.591796875 Accuracy: 98.09\n",
      "Cost and error rate at iteration i=12, j=45: Cost : 3298.0625 Accuracy: 98.09\n",
      "Cost and error rate at iteration i=12, j=90: Cost : 3329.5556640625 Accuracy: 97.9\n",
      "Cost and error rate at iteration i=13, j=0: Cost : 3314.638916015625 Accuracy: 98.08\n",
      "Cost and error rate at iteration i=13, j=45: Cost : 3324.4697265625 Accuracy: 98.0\n",
      "Cost and error rate at iteration i=13, j=90: Cost : 3369.546875 Accuracy: 97.75\n",
      "Cost and error rate at iteration i=14, j=0: Cost : 3393.86279296875 Accuracy: 97.79\n",
      "Cost and error rate at iteration i=14, j=45: Cost : 3396.57177734375 Accuracy: 97.66\n",
      "Cost and error rate at iteration i=14, j=90: Cost : 3417.043701171875 Accuracy: 97.54\n",
      "Cost and error rate at iteration i=15, j=0: Cost : 3425.343994140625 Accuracy: 97.49\n",
      "Cost and error rate at iteration i=15, j=45: Cost : 3400.00927734375 Accuracy: 97.65\n",
      "Cost and error rate at iteration i=15, j=90: Cost : 3372.4619140625 Accuracy: 97.75\n",
      "Cost and error rate at iteration i=16, j=0: Cost : 3421.29638671875 Accuracy: 97.57\n",
      "Cost and error rate at iteration i=16, j=45: Cost : 3333.55712890625 Accuracy: 97.84\n",
      "Cost and error rate at iteration i=16, j=90: Cost : 3350.828125 Accuracy: 97.79\n",
      "Cost and error rate at iteration i=17, j=0: Cost : 3332.2470703125 Accuracy: 97.83\n",
      "Cost and error rate at iteration i=17, j=45: Cost : 3326.2744140625 Accuracy: 98.02\n",
      "Cost and error rate at iteration i=17, j=90: Cost : 3286.935546875 Accuracy: 98.02\n",
      "Cost and error rate at iteration i=18, j=0: Cost : 3283.974609375 Accuracy: 98.04\n",
      "Cost and error rate at iteration i=18, j=45: Cost : 3278.694091796875 Accuracy: 98.16\n",
      "Cost and error rate at iteration i=18, j=90: Cost : 3259.2578125 Accuracy: 98.2\n",
      "Cost and error rate at iteration i=19, j=0: Cost : 3280.825927734375 Accuracy: 98.08\n",
      "Cost and error rate at iteration i=19, j=45: Cost : 3271.258056640625 Accuracy: 98.15\n",
      "Cost and error rate at iteration i=19, j=90: Cost : 3241.331298828125 Accuracy: 98.32\n",
      "Cost and error rate at iteration i=20, j=0: Cost : 3242.34228515625 Accuracy: 98.28\n",
      "Cost and error rate at iteration i=20, j=45: Cost : 3243.707275390625 Accuracy: 98.26\n",
      "Cost and error rate at iteration i=20, j=90: Cost : 3234.73681640625 Accuracy: 98.25\n",
      "Cost and error rate at iteration i=21, j=0: Cost : 3231.68359375 Accuracy: 98.31\n",
      "Cost and error rate at iteration i=21, j=45: Cost : 3226.3046875 Accuracy: 98.35\n",
      "Cost and error rate at iteration i=21, j=90: Cost : 3219.9912109375 Accuracy: 98.34\n",
      "Cost and error rate at iteration i=22, j=0: Cost : 3220.8369140625 Accuracy: 98.32\n",
      "Cost and error rate at iteration i=22, j=45: Cost : 3220.2041015625 Accuracy: 98.32\n",
      "Cost and error rate at iteration i=22, j=90: Cost : 3217.438232421875 Accuracy: 98.32\n",
      "Cost and error rate at iteration i=23, j=0: Cost : 3215.77880859375 Accuracy: 98.32\n",
      "Cost and error rate at iteration i=23, j=45: Cost : 3217.9287109375 Accuracy: 98.33\n",
      "Cost and error rate at iteration i=23, j=90: Cost : 3215.294677734375 Accuracy: 98.34\n",
      "Cost and error rate at iteration i=24, j=0: Cost : 3215.642333984375 Accuracy: 98.34\n",
      "Cost and error rate at iteration i=24, j=45: Cost : 3218.12548828125 Accuracy: 98.37\n",
      "Cost and error rate at iteration i=24, j=90: Cost : 3217.148681640625 Accuracy: 98.37\n",
      "------------------------------TEST------------------------------------\n",
      "Cost and error rate at iteration i=24, j=99: Cost : 3184.64453125 Accuracy: 98.53\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f831465f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "\n",
    "    hidden_layer_sizes = [400,300,100,50,20]\n",
    "    neural_network = NeuralNetwork(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                                   dataset=load_dataset,\n",
    "                                   )\n",
    "    neural_network.fit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
