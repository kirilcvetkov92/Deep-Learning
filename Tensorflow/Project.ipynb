{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Define Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer:\n",
    "    def __init__(self, M, D, activation=tf.nn.relu):\n",
    "        self.W = self.init_w(M,D)\n",
    "        self.b = self.init_b(D)\n",
    "        self.activation = activation\n",
    "\n",
    "    def init_w(self, M, D):\n",
    "        #XAVIER UNIFORM WEIGHT INITIALIZATION\n",
    "        return tf.Variable(initial_value = np.random.randn(M, D) / np.sqrt(M+D),\n",
    "                           dtype='float32'\n",
    "                           )\n",
    "\n",
    "    def init_b(self, D):\n",
    "        #INITIALIZE THE BIAS TERM WITH ZEROS\n",
    "        return tf.Variable(initial_value = np.zeros(D),\n",
    "                           dtype='float32')\n",
    "\n",
    "    def get_params(self):\n",
    "        #get parameters from hidden layer\n",
    "        return [self.W, self.b]\n",
    "\n",
    "    def get_layer_size(self):\n",
    "        return self.D\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.activation == tf.nn.relu:\n",
    "            return self.activation(tf.matmul(X,self.W) + self.b)\n",
    "        return (tf.matmul(X,self.W) + self.b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, hidden_layer_sizes,\n",
    "                 dataset,\n",
    "                 activation=tf.nn.relu,\n",
    "                 learning_rate=5e-3,\n",
    "                 iterations=25,\n",
    "                 batch_size = 500\n",
    "                 ):\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset=dataset\n",
    "\n",
    "\n",
    "    def generate_layers(self, first_layer_size, activation_layer_size):\n",
    "        layers = []\n",
    "        prev_layer_size = first_layer_size\n",
    "        for hidden_layer_size in self.hidden_layer_sizes:\n",
    "            hidden_layer = HiddenLayer(prev_layer_size, hidden_layer_size, self.activation)\n",
    "            layers.append(hidden_layer)\n",
    "            prev_layer_size = hidden_layer_size\n",
    "\n",
    "        activation_layer = HiddenLayer(prev_layer_size, activation_layer_size, activation=None)\n",
    "        layers.append(activation_layer)\n",
    "        return layers\n",
    "\n",
    "    def get_number_of_classes(self, target):\n",
    "        return  len(set(target))\n",
    "\n",
    "    def get_cost(self, Y, T):\n",
    "        cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=Y, labels=T))\n",
    "        return cost\n",
    "\n",
    "    def fit(self, print_period=10, show_fig=True):\n",
    "        #get dataset variables\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = self.dataset(flatten=True)\n",
    "\n",
    "        #make one-hot encoding for the classes\n",
    "        Ytrain_ind = self.y_hot_encoding(y_train)\n",
    "        Ytest_ind = self.y_hot_encoding(y_test)\n",
    "        Yval_ind = self.y_hot_encoding(y_val)\n",
    "\n",
    "        # initialize hidden layers\n",
    "        N, D = X_train.shape\n",
    "\n",
    "        #get number of classes\n",
    "        K=self.get_number_of_classes(target=y_train)\n",
    "\n",
    "        #generate layers\n",
    "        self.layers = self.generate_layers(first_layer_size=D,\n",
    "                                           activation_layer_size=K)\n",
    "\n",
    "\n",
    "\n",
    "        #define placeholders\n",
    "        X = tf.placeholder(dtype=tf.float32, shape=(None, D), name='X')\n",
    "        T = tf.placeholder(dtype=tf.float32, shape=(None, K), name='T')\n",
    "\n",
    "        #make feed forward to all layers\n",
    "        Z = X\n",
    "        for layer in self.layers:\n",
    "            Z = layer.forward(Z)\n",
    "\n",
    "        #latest feed forward layer is the activation layer\n",
    "        Y_predicted = Z\n",
    "\n",
    "        #get the cost of our prediction\n",
    "        cost=self.get_cost(Y=Y_predicted,T=T)\n",
    "\n",
    "        #define the trianing optimization\n",
    "        train_op = train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "        # we'll use this to calculate the error rate\n",
    "        error_rate = tf.argmax(Y_predicted, 1)\n",
    "\n",
    "        costs = []\n",
    "\n",
    "        no_batches = self.get_number_of_batches(samples=N)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as session:\n",
    "            def validate(X_in,Y_out, Y_ind):\n",
    "                # call validation session\n",
    "                test_cost = session.run(cost, feed_dict={X: X_in, T: Y_ind})\n",
    "                # get error rate\n",
    "                prediction = session.run(error_rate, feed_dict={X: X_in})\n",
    "                err = self.error_rate(prediction, Y_out)\n",
    "                print(\"Cost / err at iteration i={0}, j={1}: {2} / {3}\".format(i, j, test_cost, err))\n",
    "                costs.append(test_cost)\n",
    "\n",
    "            session.run(init)\n",
    "            for i in range(self.iterations):\n",
    "                for j in range(no_batches):\n",
    "                    #train\n",
    "                    Xbatch = X_train[j * self.batch_size:(j * self.batch_size + self.batch_size), ]\n",
    "                    Ybatch = Ytrain_ind[j * self.batch_size:(j * self.batch_size + self.batch_size), ]\n",
    "                    #call train session\n",
    "                    session.run(train_op, feed_dict={X: Xbatch, T: Ybatch})\n",
    "\n",
    "                    #validate\n",
    "                    if j % print_period == 0:\n",
    "                        validate(X_val,y_val,Yval_ind)\n",
    "\n",
    "            print('------------------------------TEST------------------------------------')\n",
    "            # call validation session\n",
    "            validate(X_test,y_test,Ytest_ind)\n",
    "\n",
    "\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "    def error_rate(self, p, t):\n",
    "        return np.mean(p != t)\n",
    "\n",
    "    def get_number_of_batches(self, samples):\n",
    "        if self.batch_size is None:\n",
    "            self.batch_size = samples\n",
    "\n",
    "        batches = samples // self.batch_size\n",
    "        return batches\n",
    "\n",
    "    def y_hot_encoding(self, Y):\n",
    "        N = len(Y)\n",
    "        K = len(set(Y))\n",
    "        hot_encoding = np.zeros((N, K))\n",
    "        hot_encoding[np.arange(N), Y] = 1\n",
    "        return hot_encoding\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "\n",
    "    hidden_layer_sizes = [300,100,50,20]\n",
    "    neural_network = NeuralNetwork(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                                   dataset=load_dataset,\n",
    "                                   )\n",
    "    neural_network.fit()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
